# -*- coding: utf-8 -*-
"""DataAnalystIntern.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KMh31xZBYDEUvTM8R4vglyZggXdW8DcW
"""

import os

file_path = '/content/Titanic-Dataset.csv'
if os.path.exists(file_path):
    df = pd.read_csv(file_path)
    print("File loaded successfully!")
else:
    print("File not found. Please check the path.")

if 'Fare' in df.columns:
    mean_fare = df['Fare'].mean()
    median_fare = df['Fare'].median()
    mode_fare = df['Fare'].mode()[0]
    std_fare = df['Fare'].std()

    print(f"Mean: {mean_fare}")
    print(f"Median: {median_fare}")
    print(f"Mode: {mode_fare}")
    print(f"Standard Deviation: {std_fare}")
else:
    print("'Fare' column not found in the dataset.")

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler


df = pd.read_csv('/content/Titanic-Dataset.csv')

print("Missing values before cleaning:\n", df.isnull().sum())

df.dropna(inplace=True)

df.drop_duplicates(inplace=True)

print("Data types before conversion:\n", df.dtypes)

if 'Fare' in df.columns:
    df['Fare'] = pd.to_numeric(df['Fare'], errors='coerce')
    df['Fare'] = df['Fare'].astype('int', errors='ignore')

def remove_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

if 'Fare' in df.columns:
    df = remove_outliers_iqr(df, 'Fare')

scaler = StandardScaler()

if 'Fare' in df.columns and 'Age' in df.columns:
    df[['Fare', 'Age']] = scaler.fit_transform(df[['Fare', 'Age']])

df.rename(columns={'old_column_name': 'new_column_name'}, inplace=True)

print("Missing values after cleaning:\n", df.isnull().sum())

print("Cleaned dataset:\n", df.head())

import pandas as pd

df = pd.read_csv('/content/Iris.csv')

duplicates = df[df.duplicated()]
print("Duplicate rows in the dataset:")
print(duplicates)

print(f"Number of duplicate rows: {duplicates.shape[0]}")

df_cleaned = df.drop_duplicates()

print(f"Number of rows after removing duplicates: {df_cleaned.shape[0]}")
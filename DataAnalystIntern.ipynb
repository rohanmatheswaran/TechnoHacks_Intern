{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWWpyu7tN8yXQO7W9kPJPl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohanmatheswaran/TechnoHacks_Intern/blob/main/DataAnalystIntern.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = '/content/Titanic-Dataset.csv'\n",
        "if os.path.exists(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"File loaded successfully!\")\n",
        "else:\n",
        "    print(\"File not found. Please check the path.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK0anjcZ4khO",
        "outputId": "9d238574-5d2b-4aad-e893-ab66d1629628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if 'Fare' in df.columns:\n",
        "    mean_fare = df['Fare'].mean()\n",
        "    median_fare = df['Fare'].median()\n",
        "    mode_fare = df['Fare'].mode()[0]\n",
        "    std_fare = df['Fare'].std()\n",
        "\n",
        "    print(f\"Mean: {mean_fare}\")\n",
        "    print(f\"Median: {median_fare}\")\n",
        "    print(f\"Mode: {mode_fare}\")\n",
        "    print(f\"Standard Deviation: {std_fare}\")\n",
        "else:\n",
        "    print(\"'Fare' column not found in the dataset.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P3PqQAR4vqP",
        "outputId": "107b5175-d451-4ee3-90b0-4154e14a0fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 32.204207968574636\n",
            "Median: 14.4542\n",
            "Mode: 8.05\n",
            "Standard Deviation: 49.6934285971809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/Titanic-Dataset.csv')\n",
        "\n",
        "print(\"Missing values before cleaning:\\n\", df.isnull().sum())\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "print(\"Data types before conversion:\\n\", df.dtypes)\n",
        "\n",
        "if 'Fare' in df.columns:\n",
        "    df['Fare'] = pd.to_numeric(df['Fare'], errors='coerce')\n",
        "    df['Fare'] = df['Fare'].astype('int', errors='ignore')\n",
        "\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "if 'Fare' in df.columns:\n",
        "    df = remove_outliers_iqr(df, 'Fare')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "if 'Fare' in df.columns and 'Age' in df.columns:\n",
        "    df[['Fare', 'Age']] = scaler.fit_transform(df[['Fare', 'Age']])\n",
        "\n",
        "df.rename(columns={'old_column_name': 'new_column_name'}, inplace=True)\n",
        "\n",
        "print(\"Missing values after cleaning:\\n\", df.isnull().sum())\n",
        "\n",
        "print(\"Cleaned dataset:\\n\", df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGNdrKtBHohQ",
        "outputId": "2679aa60-0ef8-4d8a-a9a0-aab8fa1eb69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before cleaning:\n",
            " PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Cabin          0\n",
            "Embarked       0\n",
            "dtype: int64\n",
            "Data types before conversion:\n",
            " PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Sex             object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "Cabin           object\n",
            "Embarked        object\n",
            "dtype: object\n",
            "Missing values after cleaning:\n",
            " PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Cabin          0\n",
            "Embarked       0\n",
            "dtype: int64\n",
            "Cleaned dataset:\n",
            "    PassengerId  Survived  Pclass  \\\n",
            "0            2         1       1   \n",
            "1            4         1       1   \n",
            "2            7         0       1   \n",
            "4           12         1       1   \n",
            "6           24         1       1   \n",
            "\n",
            "                                                Name     Sex       Age  SibSp  \\\n",
            "0  Cumings, Mrs. John Bradley (Florence Briggs Th...  female -0.034424      1   \n",
            "1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female -0.226446      1   \n",
            "2                            McCarthy, Mr. Timothy J    male  0.989693      0   \n",
            "4                           Bonnell, Miss. Elizabeth  female  1.245723      0   \n",
            "6                       Sloper, Mr. William Thompson    male -0.674497      0   \n",
            "\n",
            "   Parch    Ticket  Fare Cabin Embarked  \n",
            "0      0  PC 17599   0.0   C85        C  \n",
            "1      0    113803   0.0  C123        S  \n",
            "2      0     17463   0.0   E46        S  \n",
            "4      0    113783   0.0  C103        S  \n",
            "6      0    113788   0.0    A6        S  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/Iris.csv')\n",
        "\n",
        "duplicates = df[df.duplicated()]\n",
        "print(\"Duplicate rows in the dataset:\")\n",
        "print(duplicates)\n",
        "\n",
        "print(f\"Number of duplicate rows: {duplicates.shape[0]}\")\n",
        "\n",
        "df_cleaned = df.drop_duplicates()\n",
        "\n",
        "print(f\"Number of rows after removing duplicates: {df_cleaned.shape[0]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy5LPeXSJbqG",
        "outputId": "6f445d9d-5fd8-4658-c6ba-11b109f066e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate rows in the dataset:\n",
            "Empty DataFrame\n",
            "Columns: [Id, SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm, Species]\n",
            "Index: []\n",
            "Number of duplicate rows: 0\n",
            "Number of rows after removing duplicates: 150\n"
          ]
        }
      ]
    }
  ]
}